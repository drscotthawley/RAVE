[DEFAULTS]

# name of the run. don't leave this blank
name = None

# batch size
batch = 8

# random seed
seed = 42

# accelerate start method
start_method = "forkserver"

# IDK
data_size = 16

# IDK
capacity = 32

# size of latent embeddings
latent_size = 128

# ratios of sizes between layers
ratios = [4, 4, 2, 2, 2]

# IDK
taylor_degrees = 0

# IDK
bias = True

# IDK
no_latency = False


# IDK
min_kl = 1e-4

# IDK
max_kl = 1e-1

# IDK
cropped_latent_size = 0

# IDK
feature_match = True

# IDK
loud_stride = 1

# IDK
use_noise = True

# IDK
noise_ratios = [4, 4, 4]

# IDK
noise_bands = 5

# IDK
d_capacity = 16

# IDK
d_multiplier = 4

# IDK
d_n_layers = 4

# IDK
warmup = 40100

# IDK
mode = "hinge"


# UNUSED NOW. where preprocessed audio is/will be stored (left in so scripts don't break)
preprocessed = None


# where original-audio dataset is stored
wav = None

# sample rate in Hz
sr = 48000

# how long each 'chunk' of audio is
n_signal = 65536

# IDK
max_steps = 20000000

# how often (in steps) to perform validation measures
val_every = 4000

# how often to save a checkpoint
checkpoint_every = 20000

# name of checkpoint file (to start from)
ckpt = None

# UNUSED - from antoine's code: list of transformations (as a string)
transforms = [RandomCrop(args.n_signal), Dequantize(16), lambda x: x.astype(np.float32)]

# replaces transforms = list (w/o brackets) of augmentation transfroms (in audiodata.py) to apply 
augs = Mono(), PhaseFlipper()


# fraction of total dataset to use
load_frac = 1.0

# number of nodes 
num_nodes = 16 

# number of gpus
num_gpus = 8

# how often (in steps) to check for updates to the ofc / args file
check_ofc_every = 50

